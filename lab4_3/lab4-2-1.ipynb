{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of lab4-2-1.ipynb","provenance":[{"file_id":"https://github.com/cs236299-2020/lab4-2b/blob/master/lab4-2b.ipynb","timestamp":1611048872908}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"title":"236299 Lab 4-2B: Semantic ambiguity and quantifier scope"},"cells":[{"cell_type":"code","metadata":{"deletable":false,"editable":false,"jupyter":{"outputs_hidden":true,"source_hidden":true},"id":"J00F_4gJ_ROb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087491250,"user_tz":-120,"elapsed":11828,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"358a3918-2e74-473c-bf58-2fd5ea0bce5c"},"source":["# Please do not change this cell because some hidden tests might depend on it.\n","import os\n","\n","# Otter grader does not handle ! commands well, so we define and use our\n","# own function to execute shell commands.\n","def shell(commands, warn=True):\n","    \"\"\"Executes the string `commands` as a sequence of shell commands.\n","     \n","       Prints the result to stdout and returns the exit status. \n","       Provides a printed warning on non-zero exit status unless `warn` \n","       flag is unset.\n","    \"\"\"\n","    file = os.popen(commands)\n","    print (file.read().rstrip('\\n'))\n","    exit_status = file.close()\n","    if warn and exit_status != None:\n","        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n","    return exit_status\n","\n","shell(\"\"\"\n","ls requirements.txt >/dev/null 2>&1\n","if [ ! $? = 0 ]; then\n"," rm -rf .tmp\n"," git clone https://github.com/cs236299-2020/lab4-2b.git .tmp\n"," mv .tmp/tests ./\n"," mv .tmp/requirements.txt ./\n"," rm -rf .tmp\n","fi\n","pip install -q -r requirements.txt\n","\"\"\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"zzmNHEQ__ROg","executionInfo":{"status":"ok","timestamp":1611087491678,"user_tz":-120,"elapsed":12224,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["# Initialize Otter\n","import otter\n","grader = otter.Notebook()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GKCmoKBP_ROi"},"source":["# Course 236299"]},{"cell_type":"markdown","metadata":{"id":"HIUs28Vq-KDU"},"source":["## Lab 4-2B – Semantic ambiguity and quantifier scope"]},{"cell_type":"markdown","metadata":{"id":"1b1avlsK_ROl"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"ahKelu4V_ROm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087491682,"user_tz":-120,"elapsed":12209,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"d639d012-aef2-4dce-f286-904215a3fcf3"},"source":["# Download code for transforming grammars\n","shell(\"\"\"\n","  wget -nv -N -P scripts https://raw.githubusercontent.com/nlp-236299/data/master/scripts/trees/transform.py\n","\"\"\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GYPSuQr2_ROn","executionInfo":{"status":"ok","timestamp":1611087493683,"user_tz":-120,"elapsed":14193,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["import sys\n","\n","import nltk\n","\n","# Import functions for transforming augmented grammars\n","sys.path.insert(1, './scripts')\n","import transform as xform"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BOrUNzos-OqG"},"source":["## Introduction\n","\n","When discussing syntactic representations, we encountered a central issue in natural language — ambiguity. In lab 3-3, we introduced PP attachment ambiguity to show how a single sentence (\"Twain bought a book for Howells\") can have multiple distinct syntactic structures, each bearing different meanings. \n","\n","Semantic ambiguity can arise even for a single parse of a sentence giving rise to different meanings. In this lab, we'll introduce one example of this phenomenon, quantifier scope ambiguity. We'll take a look at a sentence that elicits this type of ambiguity, propose two possible FOL representations of the sentence, confirming that they produce different truth values in a model. Then, we will use a syntactic-semantic grammar similar to those of lab 4-1 to parse the sentence, pointing out a weakness of this method.\n","\n","## The flight world model\n","\n","We'll be using the flight world as the domain for the lab, so we provide a simple model for it here."]},{"cell_type":"code","metadata":{"id":"zzNJGn2NeaEF","executionInfo":{"status":"ok","timestamp":1611087493724,"user_tz":-120,"elapsed":14218,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["# Constants\n","\n","London = \"London\"\n","NewYork = \"New York\"\n","Paris = \"Paris\"\n","Boston = \"Boston\"\n","TelAviv = \"Tel Aviv\"\n","\n","DL10 = \"DL10\"\n","DL11 = \"DL11\"\n","DL13 = \"DL13\"\n","LY01 = \"LY01\"\n","LY12 = \"LY12\"\n","\n","# Predicates\n","Object = {London, NewYork, Paris, Boston, TelAviv,\n","          DL10, DL11, DL13, LY01, LY12}\n","Flight = {DL10, DL11, DL13, LY01, LY12}\n","City = {London, Paris, NewYork, Boston, TelAviv}\n","Capital = {London, Paris}\n","Origin = {(DL10, London), (DL11, London), (DL13, Paris), (LY01, Paris), (LY12, London)}\n","Destination = {(DL10, NewYork), (DL11, TelAviv), (DL13, Boston), (LY01, NewYork), (LY12, TelAviv)}"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RxgbfWdf_ROp"},"source":["## Quantifier meanings\n","\n","Before discussing quantifier scope ambiguity, we need to establish an appropriate notion of quantifier meanings in natural language. In FOL, there are only two quantifiers, the universal quantifier $\\forall$ (\"for all\") and the existential quantifier $\\exists$ (\"there exists\"). In natural language, we find many more quantifiers. A few examples:\n","\n","* Universal: \"every\", \"each\"\n","* Existential: \"some\", \"a(n)\"\n","* Exact counts: \"one\", \"two\", \"three\", \"infinitely many\"\n","* Approximate counts: \"few\", \"many\", \"most\", \"several\"\n","* Count bounds: \"more than three\", \"fewer than 100\""]},{"cell_type":"markdown","metadata":{"id":"oYXLURPu_ROr"},"source":["Natural language quantifiers can be thought of as expressing a _relationship between two properties_. \n","\n","> Recall that a _property_ can be thought of as a set of objects (those bearing the property) or a function from objects to truth values (which takes the objects that bear the property to _true_ and objects not bearing the property to false). In our flight world, $Flight$ is a property, as is $\\lambda x. Origin(x, Boston)$ (\"objects originating in Boston\").\n","\n","Natural language quantifiers like \"every\" express a relationship between two properties, the _restriction_ of the quantifier and the _scope_ of the quantifier. For instance, in the sentence \"every flight leaves from Boston\", the restriction property is expressed by  \"flight\" and the scope property is expressed by \"leaves from Boston\". The relationship that \"every\" expresses is simply that everything bearing the first property also bears the second. Similarly, \"some\" expresses the relationship that there is something bearing the first property that also bears the second property. And \"most\" expresses that most (at least half, say) of the objects bearing the first property bear the second property.\n","\n","This way of thinking about quantifiers as expressing relationships between two properties is referred to as [_generalized quantifiers_](https://en.wikipedia.org/wiki/Generalized_quantifier), because it generalizes the FOL notion of quantifier by adding an explicit and separate restriction.\n","\n","> In FOL, quantifiers $\\forall$ and $\\exists$ have only a scope and not a restriction. When we write $\\forall x. \\ldots$, the $\\ldots$ is the scope of the quantifier; we can think of this as expressing that $\\forall$ holds of the single property $\\lambda x. \\ldots$. How then can restriction properties be expressed in FOL? By folding them into the scope.\n",">    * \"every flight leaves from Boston\": $\\forall x. Flight(x) \\Longrightarrow Origin(x, Boston)$\n",">    * \"some flight leaves from Boston\": $\\exists x. Flight(x) \\land Origin(x, Boston)$\n",">\n","> Notice though that in incorporating the restriction ($Flight(x)$) into the scope of the FOL quantifier, we use different ways of combining them depending on the quantifier. That's somewhat inelegant. More importantly, for most NL quantifiers, _there is no way of encoding the relationship between restriction and scope with just a single property_, as we happen to be able to for the universal and existential quantifiers. Hence, semanticists have moved to the generalized quantifier approach to quantifier meanings, as we do here.\n","\n","To allow for meanings for the first order quantifiers, we'll define some Python functions that capture this generalized quantifier approach. Each quantifier function takes the two properties, restriction and scope, and returns a truth value."]},{"cell_type":"code","metadata":{"id":"KKQyPrCD_ROs","executionInfo":{"status":"ok","timestamp":1611087493726,"user_tz":-120,"elapsed":14204,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["def for_all(R_property, S_property):\n","  \"\"\"Returns `true` just in case all objects bearing `R_property`\n","     also have `S_property`.\"\"\"\n","  restriction_objects = [x for x in Object if R_property(x)]\n","  scope_objects = [x for x in Object if S_property(x)]\n","  return all([x in scope_objects for x in restriction_objects])\n","\n","def there_exists(R_property, S_property):\n","  \"\"\"Returns `true` just in case at least one object bearing `R_property`\n","     also has `S_property`.\"\"\"\n","  restriction_objects = [x for x in Object if R_property(x)]\n","  scope_objects = [x for x in Object if S_property(x)]\n","  return any([x in scope_objects for x in restriction_objects])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PfeoZEK5_ROu"},"source":["We can see how these work by verifying that it's not the case that all flights originate in London, but some flight does."]},{"cell_type":"code","metadata":{"id":"4jM3gTHB_ROv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493729,"user_tz":-120,"elapsed":14190,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"3ae90b72-1993-49be-b9fb-e081b07fbd6d"},"source":["## expressing \"every flight leaves from London\" -- should be false\n","for_all(lambda x: x in Flight, lambda y: (y, London) in Origin)\n","# for all x s.t Flight(x) -> Origin(x, London)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"1sd4xOhk_ROw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493732,"user_tz":-120,"elapsed":14173,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"09db0625-40b1-440d-92da-48bb392cec59"},"source":["## expressing \"some flight leaves from London\" -- should be true\n","there_exists(lambda x: x in Flight, lambda y: (y, London) in Origin)\n","# exists x s.t Flight(x) and Origin(x, London)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"uOn2dddRH-1w"},"source":["## Quantifier scope ambiguity\n","\n","Consider the sentence\n","\n","* every flight leaves from a capital\n","\n","Under one reading of this sentence, it is true just in case each flight leaves from a (possibly different) city that is a capital. This interpretation can be represented with the following FOL formula:\n","\n","$$ \\forall x. (Flight(x) \\implies \\exists y. (Capital(y) \\land Origin(x, y))) \\tag{1}$$\n","\n","However, there is another possible reading of this sentence. A less intuitive yet possible interpretation could be that we are asking if there is a single capital from which all flights leave. This interpretation gives rise to a different FOL representation: \n","\n","$$ \\exists y. (Capital(y) \\land \\forall x. (Flight(x) \\implies Origin(x, y))) \\tag{2} $$"]},{"cell_type":"markdown","metadata":{"id":"XTLoguPE_ROz"},"source":["This type of ambiguity is referred to as _quantifier scope ambiguity_, and appears almost inevitably when a sentence has multiple quantified noun phrases. \n","\n","> Other scope-taking elements can also give rise to scope ambiguities. For instance, modals (like \"may\", \"must\", \"can\"), and negation (\"not\") also have scope and can engender ambiguities. For instance, the sentence \"you may not go\" arguably has two readings, paraphrasable as \"you have permission to not go\" (that is, you may stay) and \"you do not have permission to go\" (that is, you must stay). Examining these further kinds of ambiguity is beyond the scope (so to speak) of this lab.\n","\n","It is easy to see that both representations have the same components, just structured differently. The different ordering possibilities of the quantifiers is what generates the ambiguity. In representation (1), $\\forall x$ has the outer scope, while in representation (2), $\\exists y$ has the outer scope. Reflecting this ordering, the two readings are sometimes referred to as the AE reading and the EA reading, respectively.\n","\n","> As another example of the phenomenon, consider the old joke: In my town, a person is mugged every 15 minutes...and boy is he getting tired of it."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"vPU1Dr7-_RO1"},"source":["Express the two readings of the sentence \n","\n","* every flight leaves from a capital\n","\n","using the Python implementation of generalized quantifiers. Start with the AE reading.\n","<!--\n","BEGIN QUESTION\n","name: ambiguity_AE\n","-->"]},{"cell_type":"code","metadata":{"id":"k71JqirW_RO3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493735,"user_tz":-120,"elapsed":14158,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"f66304cc-8b3e-4e50-9496-ab5f74f9532b"},"source":["AE_reading = for_all(lambda x: x in Flight, lambda x: there_exists(lambda x: x in Capital, lambda y: lambda z: (y, z) in Origin))\n","AE_reading"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"fAk-EZ0l_RO4","colab":{"base_uri":"https://localhost:8080/","height":46},"executionInfo":{"status":"ok","timestamp":1611087493739,"user_tz":-120,"elapsed":14134,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"a95d1f27-9d57-4131-f22e-aeb8db17a860"},"source":["grader.check(\"ambiguity_AE\")"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"kpalbo-__RO5"},"source":["Now do the same for the EA reading.\n","<!--\n","BEGIN QUESTION\n","name: ambiguity_EA\n","-->"]},{"cell_type":"code","metadata":{"id":"WfINnf9w_RO5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493740,"user_tz":-120,"elapsed":14106,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"1972fc1b-54a1-44c6-e92d-6f3f7e10f777"},"source":["EA_reading = there_exists(lambda x: x in Capital,lambda x: for_all(lambda x: x in Flight,lambda y: lambda z: (z,y) in Origin))\n","EA_reading"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"zVFOdqOt_RO6","colab":{"base_uri":"https://localhost:8080/","height":46},"executionInfo":{"status":"ok","timestamp":1611087493742,"user_tz":-120,"elapsed":14083,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"2dc9b0cd-2930-4835-a97f-35ad0e3c1ff7"},"source":["grader.check(\"ambiguity_EA\")"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"dTNqFRpXW0dg"},"source":["If you've implemented the two readings correctly, you have confirmed that the two readings of the ambiguous sentence are indeed different; they generate different answers."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"JIqBnppZ_RO8"},"source":["## A compositional semantics for quantifiers\n","\n","Instead of manually constructing a meaning representation as we did, let's use a syntactic-semantic grammar to perform this interpretation process. We will use the following augmented grammar: \n","<!--\n","BEGIN QUESTION\n","name: complete_grammar\n","-->"]},{"cell_type":"code","metadata":{"id":"ST0c7Sez_RO9","executionInfo":{"status":"ok","timestamp":1611087493743,"user_tz":-120,"elapsed":14059,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["grammar_spec = \"\"\" \n","  S -> NP VP                  :  lambda NP, VP: NP(VP)\n","  \n","  VP -> V NP                  :  lambda V, NP: lambda x: NP(V(x))\n","\n","  V -> 'leaves' 'from'        :  lambda: lambda Subj: lambda Obj: (Subj, Obj) in Origin\n","     | 'leave' 'from'\n","     | 'goes' 'to'            :  lambda: lambda Subj: lambda Obj: (Subj, Obj) in Destination\n","     | 'go' 'to'\n","\n","  S_COMP -> 'that' VP         :  lambda VP: VP\n","\n","  NP -> DET NOM               :  lambda DET, NOM: DET(NOM)\n","  NOM -> NOM S_COMP           :  lambda N, S: lambda x: N(x) and S(x)\n","  NOM -> N                    :  lambda x: x\n","  \n","  NP -> 'New' 'York'          :  lambda: lambda P: P(NewYork)\n","      | 'Paris'               :  lambda: lambda P: P(Paris)\n","      | 'Tel' 'Aviv'          :  lambda: lambda P: P(TelAviv)\n","      | 'London'              :  lambda: lambda P: P(London)\n","      | 'Boston'              :  lambda: lambda P: P(Boston)\n","\n","  N -> 'flight' | 'flights'   :  lambda: lambda x: x in Flight\n","     | 'capital' | 'capitals' :  lambda: lambda x: x in Capital\n","     | 'city' | 'cities'      :  lambda: lambda x: x in City\n","\n","  DET -> 'every'              :  lambda: lambda R: lambda S: for_all(R, S)\n","       | 'a'                  :  lambda: lambda R: lambda S: there_exists(R, S)\n","\"\"\""],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BvHJpG0l_RO-"},"source":["Some things to note about the grammar:\n","\n","* Some of the nonterminals may be unfamiliar. In particular, the nonterminal `S_COMP` is for complementized relative clauses, phrases like \"that leaves from Boston\" in the sentence \"every flight that leaves from Boston goes to New York\".\n","\n","* Some of the productions have no augmentation. You may recall that in this format, productions with no explicit augmentation just use the one for the preceding production. Thus the \"goes to\" and \"go to\" rules have the same augmentation.\n","\n","* Some of the augmentations (those involving `S_COMP`) raise `NotImplementedError`. We'll have you fill those in in a bit. Hold off for now.\n","\n","* As described in the introductory lecture, this grammar makes use of Richard Montague's idea that noun phrase meanings should apply to verb phrase meanings, rather than the other way around. In so doing, we allow for quantifiers within noun phrases to scope over their verb phrases. But this approach necessitates changing the types of even simple noun phrases like \"Boston\". Instead of denoting an object, it too must denote a function from properties to truth values: $\\lambda P. P(Boston)$. \n","\n","We parse the grammar specification to extract an NLTK grammar and the augmentation dictionary, and construct a parser for the grammar."]},{"cell_type":"code","metadata":{"id":"PVnV91y6_RO_","executionInfo":{"status":"ok","timestamp":1611087493746,"user_tz":-120,"elapsed":14044,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["grammar, augmentations = xform.parse_augmented_grammar(grammar_spec, globals=globals())\n","parser = nltk.parse.BottomUpChartParser(grammar)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R9arBrRXYDZ2"},"source":["Let's create a syntactic parse tree of the sentence we've been working with: "]},{"cell_type":"code","metadata":{"id":"J9C5ANDCecN4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493749,"user_tz":-120,"elapsed":14032,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"1b741c4a-4b07-416a-c89d-844a18377220"},"source":["sentence = \"every flight leaves from a capital\".split()\n","parses = [p for p in parser.parse(sentence)]\n","for tree in parses:\n","    tree.pretty_print()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["                   S                                \n","        ___________|______________                   \n","       |                          VP                \n","       |                  ________|_______           \n","       NP                |                NP        \n","   ____|____             |             ___|_____     \n","  |        NOM           |            |        NOM  \n","  |         |            |            |         |    \n"," DET        N            V           DET        N   \n","  |         |       _____|___         |         |    \n","every     flight leaves     from      a      capital\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4OrZpUzeYUbD"},"source":["To carry out the semantic interpretation process, we will use the same notation as in lab 4-1, where the variable `A__some_words` will be given the meaning for the constituent with nonterminal `A` with the span \"some words\". We start building the semantic representation by applying the semantic composition rules from the syntactic-semantic grammar to the meanings of the subconstituents bottom up. Here are the first few steps:"]},{"cell_type":"code","metadata":{"id":"EttS-qJa_RPD","executionInfo":{"status":"ok","timestamp":1611087493751,"user_tz":-120,"elapsed":14010,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["DET__every = (lambda: lambda R: lambda S: for_all(R, S)) () # lambda R: lambda S: for_all(R, S)\n","N__flight = (lambda: lambda x: x in Flight) () # lambda x: x in Flight\n","NOM__flight = (lambda X: X) (N__flight) # lambda x: x in Flight\n","NP__every_flight = (lambda DET, NN: DET(NN)) (DET__every, NOM__flight) # lambda S: for_all(lambda x: x in Flight, S)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"FR7X4pT-_RPD"},"source":["Now you complete the derivation, computing the meanings for each of the remaining constituents.\n","<!--\n","BEGIN QUESTION\n","name: complete_derivation\n","-->"]},{"cell_type":"code","metadata":{"id":"B-fEpagP_RPD","executionInfo":{"status":"ok","timestamp":1611087493754,"user_tz":-120,"elapsed":13993,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["DET__a = (lambda: lambda R: lambda S: there_exists(R, S))()\n","N__capital = (lambda: lambda x: x in Capital)()\n","NOM__capital = (lambda x: x)(N__capital)\n","NP__a_capital = (lambda DET, NOM: DET(NOM))(DET__a,NOM__capital)\n","V__leaves_from = (lambda: lambda Subj: lambda Obj: (Subj, Obj) in Origin)()\n","VP__leaves_from_a_capital = (lambda V, NP: lambda x: NP(V(x)))(V__leaves_from,NP__a_capital)\n","S__every_flight_leaves_from_a_capital = (lambda NP, VP: NP(VP))(NP__every_flight,VP__leaves_from_a_capital)\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"fUFt4G8a_RPE","colab":{"base_uri":"https://localhost:8080/","height":46},"executionInfo":{"status":"ok","timestamp":1611087493759,"user_tz":-120,"elapsed":13981,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"3d22df85-8c65-4ea5-c5b3-0aeebdba54de"},"source":["grader.check(\"complete_derivation\")"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"XfhEKjRU_RPE"},"source":["Now that you've completed the semantic derivation, let's see what truth value the model provides for this sentence."]},{"cell_type":"code","metadata":{"id":"OCJJ2jPL_RPF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493763,"user_tz":-120,"elapsed":13966,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"4524d745-9a61-46ca-94bd-39f2bbcc130b"},"source":["S__every_flight_leaves_from_a_capital"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"nM2LcVbEKzlP"},"source":["<!-- BEGIN QUESTION -->\n","\n","According to the result, which of the two readings for the sentence (AE or EA) do you think the augmented grammar produced? Can we get the other reading with the same augmented grammar? What problems do you see resulting from this behavior?\n","\n","<!--\n","BEGIN QUESTION\n","name: ambiguity_open_question\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"1FCTsMbO_RPF"},"source":["_We think the augumented grammar produced is AE. We think we can't get the other reading, at least with the current semantics. The problem can rise when an ambiguity sentence rises and the sematics choose one of the reading options over the other, regardless of the actual correct reading, which can be the reading the sematic chose but can also be the one it didn't...._"]},{"cell_type":"markdown","metadata":{"id":"7tREFWkt_RPG"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","## Extending the grammar\n","\n","To make the language more interesting, we'll extend the grammar to allow for relative clauses like \"that leaves from Boston\" or \"that goes to a capital\". Fill in the augmentations that raise `NotImplementedError` in the grammar above to allow for these. "]},{"cell_type":"code","metadata":{"id":"P5RnGfVk_RPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493767,"user_tz":-120,"elapsed":13956,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"b6a2ba24-117c-4a06-a66a-ecd631141a9f"},"source":["sentence = \"every flight that goes to Tel Aviv goes to a capital\"\n","parse = list(parser.parse(sentence.split()))[0]\n","parse.pretty_print()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["                                       S                                           \n","         ______________________________|_________________________                   \n","        NP                                                       |                 \n","   _____|__________                                              |                  \n","  |               NOM                                            VP                \n","  |      __________|_________                             _______|_______           \n","  |     |                  S_COMP                        |               NP        \n","  |     |      ______________|_____                      |            ___|_____     \n","  |    NOM    |                    VP                    |           |        NOM  \n","  |     |     |          __________|_______              |           |         |    \n"," DET    N     |         V                  NP            V          DET        N   \n","  |     |     |     ____|____           ___|___      ____|___        |         |    \n","every flight that goes       to       Tel     Aviv goes      to      a      capital\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"1iq-p59f_RPG"},"source":["To test the extended grammar, we'll make use of the `interpret` function you implemented in lab 4-2. The skeleton is provided here for your convenience. Copy in your solution.\n","\n","<!--\n","BEGIN QUESTION\n","name: grammar_extension\n","-->"]},{"cell_type":"code","metadata":{"id":"lGbXFwiO_RPH","executionInfo":{"status":"ok","timestamp":1611087493769,"user_tz":-120,"elapsed":13944,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["def interpret(tree, augmentations):\n","  function = augmentations[tree.productions()[0]]\n","  childList=[]\n","  for child in tree:\n","    if(isinstance(child,nltk.Tree)):\n","      childList.append(interpret(child,augmentations))\n","  return function(*childList)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"b4kvqfZ1_RPI","colab":{"base_uri":"https://localhost:8080/","height":46},"executionInfo":{"status":"ok","timestamp":1611087493772,"user_tz":-120,"elapsed":13933,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"c80f0e86-d32b-41e2-ed16-72e9fec8e146"},"source":["grader.check(\"grammar_extension\")"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    "],"text/plain":["\n","    All tests passed!\n","    "]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"hAlBLyfB_RPJ"},"source":["Now we can demonstrate the full range of this grammar fragment by testing out a bunch of different sentences to determine which are true and which are false"]},{"cell_type":"code","metadata":{"id":"77T96TCZ_RPK","executionInfo":{"status":"ok","timestamp":1611087493775,"user_tz":-120,"elapsed":13915,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}}},"source":["def test(sentence):\n","  print(sentence)\n","  parses = parser.parse(sentence.split())\n","  for parse in parses:\n","    print(parse, \"\\n==>\", interpret(parse, augmentations))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLLjcquT_RPK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087493777,"user_tz":-120,"elapsed":13906,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"7e92fe5a-9e2c-4238-9d24-ab7a64954f2d"},"source":["test(\"every flight goes to a capital\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["every flight goes to a capital\n","(S\n","  (NP (DET every) (NOM (N flight)))\n","  (VP (V goes to) (NP (DET a) (NOM (N capital))))) \n","==> False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0RFFTCwN_RPK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087494104,"user_tz":-120,"elapsed":14225,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"8951c610-ab0f-4af5-d3c6-033a88fa1b38"},"source":["test(\"a flight leaves from Paris\")"],"execution_count":25,"outputs":[{"output_type":"stream","text":["a flight leaves from Paris\n","(S (NP (DET a) (NOM (N flight))) (VP (V leaves from) (NP Paris))) \n","==> True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V4Tm54nS_RPL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087494106,"user_tz":-120,"elapsed":14214,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"4b4ab284-5fa0-41b4-a5a3-ff688dea1353"},"source":["test(\"a flight leaves from London\")"],"execution_count":26,"outputs":[{"output_type":"stream","text":["a flight leaves from London\n","(S (NP (DET a) (NOM (N flight))) (VP (V leaves from) (NP London))) \n","==> True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"56dR5y5V_RPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087494108,"user_tz":-120,"elapsed":14210,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"46668079-3d0b-446c-dbe7-f9d9771b202f"},"source":["test(\"every flight that goes to Tel Aviv goes to a capital\")"],"execution_count":27,"outputs":[{"output_type":"stream","text":["every flight that goes to Tel Aviv goes to a capital\n","(S\n","  (NP\n","    (DET every)\n","    (NOM\n","      (NOM (N flight))\n","      (S_COMP that (VP (V goes to) (NP Tel Aviv)))))\n","  (VP (V goes to) (NP (DET a) (NOM (N capital))))) \n","==> False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SroLOYYV_RPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087494109,"user_tz":-120,"elapsed":14205,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"3899185d-2da9-405d-e712-94a2b63943e6"},"source":["test(\"every flight that leaves from a capital goes to a capital\")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["every flight that leaves from a capital goes to a capital\n","(S\n","  (NP\n","    (DET every)\n","    (NOM\n","      (NOM (N flight))\n","      (S_COMP\n","        that\n","        (VP (V leaves from) (NP (DET a) (NOM (N capital)))))))\n","  (VP (V goes to) (NP (DET a) (NOM (N capital))))) \n","==> False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SfkPwn0__RPN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087494111,"user_tz":-120,"elapsed":14204,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"9ffcefe9-1b53-47cc-b418-e96ccf451ac1"},"source":["test(\"every flight that goes to a capital leaves from a capital\")"],"execution_count":29,"outputs":[{"output_type":"stream","text":["every flight that goes to a capital leaves from a capital\n","(S\n","  (NP\n","    (DET every)\n","    (NOM\n","      (NOM (N flight))\n","      (S_COMP that (VP (V goes to) (NP (DET a) (NOM (N capital)))))))\n","  (VP (V leaves from) (NP (DET a) (NOM (N capital))))) \n","==> True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kOkOdCyd_RPN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611087494114,"user_tz":-120,"elapsed":14201,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"85c5a283-4aff-4a48-ed9f-a5489e868ab5"},"source":["test(\"every flight that goes to a city leaves from a capital\")"],"execution_count":30,"outputs":[{"output_type":"stream","text":["every flight that goes to a city leaves from a capital\n","(S\n","  (NP\n","    (DET every)\n","    (NOM\n","      (NOM (N flight))\n","      (S_COMP that (VP (V goes to) (NP (DET a) (NOM (N city)))))))\n","  (VP (V leaves from) (NP (DET a) (NOM (N capital))))) \n","==> True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"eXiPGL_h_RPO"},"source":["<!-- BEGIN QUESTION -->\n","\n","---\n","\n","## Lab debrief – for consensus submission only\n","\n","**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n","\n","* Was the lab too long or too short?\n","* Were the readings appropriate for the lab? \n","* Was it clear (at least after you completed the lab) what the points of the exercises were? \n","* Are there additions or changes you think would make the lab better?\n","\n","<!--\n","BEGIN QUESTION\n","name: open_response_debrief\n","manual: true\n","-->"]},{"cell_type":"markdown","metadata":{"id":"0u1PHfBC_RPP"},"source":["_Type your answer here, replacing this text._"]},{"cell_type":"markdown","metadata":{"id":"KWJCTQrm_RPP"},"source":["<!-- END QUESTION -->\n","\n","\n","\n","# End of Lab 4-2B"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"JJD0iIOy_RPQ"},"source":["---\n","\n","To double-check your work, the cell below will rerun all of the autograder tests."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"MmlGhdUL_RPR","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"ok","timestamp":1611087494117,"user_tz":-120,"elapsed":14200,"user":{"displayName":"Shaked8888","photoUrl":"","userId":"04935385753347870629"}},"outputId":"bed7e776-fe09-4351-e45c-e378f59d24e0"},"source":["grader.check_all()"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<p><strong>ambiguity_AE:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>ambiguity_EA:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>complete_derivation:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n","<p><strong>grammar_extension:</strong></p>\n","\n","    \n","    \n","        <p>All tests passed!</p>\n","    \n","    \n","\n"],"text/plain":["ambiguity_AE:\n","\n","    All tests passed!\n","    \n","\n","ambiguity_EA:\n","\n","    All tests passed!\n","    \n","\n","complete_derivation:\n","\n","    All tests passed!\n","    \n","\n","grammar_extension:\n","\n","    All tests passed!\n","    \n"]},"metadata":{"tags":[]},"execution_count":31}]}]}